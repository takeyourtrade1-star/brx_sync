# Analisi ScalabilitÃ  - BRX Sync Microservice

## Obiettivo
Verificare che il sistema sia in grado di gestire molti utenti simultanei senza problemi di performance, deadlock, o esaurimento risorse.

---

## âœ… PUNTI DI FORZA (GiÃ  Implementati)

### 1. Rate Limiting Per-User âœ…
- **Isolamento**: Ogni utente ha il proprio bucket Redis (`rate_limit:{user_id}`)
- **ScalabilitÃ **: Supporta migliaia di utenti senza interferenze
- **Algoritmo**: Token Bucket distribuito via Redis
- **Adattivo**: Si adatta automaticamente ai 429 di CardTrader

### 2. Connection Pooling PostgreSQL âœ…
- **Pool Size**: 25 connessioni base
- **Max Overflow**: 50 connessioni aggiuntive
- **Totale**: Max 75 connessioni simultanee
- **Pre-ping**: Verifica connessioni morte
- **Recycle**: Rinnova connessioni ogni ora

### 3. MySQL Connection Pool âœ…
- **Pool Size**: 5 connessioni base
- **Max Overflow**: 5 connessioni aggiuntive
- **Totale**: Max 10 connessioni simultanee
- **Thread-safe**: Usa Queue con lock

### 4. Isolamento Chunk Bulk Sync âœ…
- Ogni chunk ha sessione DB isolata
- Evita race conditions e deadlock
- Parallelizzazione sicura

### 5. Deadlock Retry âœ…
- Retry automatico con exponential backoff
- Max 3 tentativi
- Rileva errori PostgreSQL 40001 e 40P01

### 6. Transaction Timeout âœ…
- Timeout configurabile (default 30s)
- Previene transazioni infinite
- Rollback automatico

### 7. Pattern Saga per Purchase âœ…
- Chiamate API fuori transazione
- Lock DB minimo
- Compensazione automatica

---

## âš ï¸ PROBLEMI POTENZIALI IDENTIFICATI

### 1. ðŸ”´ CRITICO: Redis Sync Connection Pool Mancante

**Problema**:
```python
def get_redis_sync():
    return redis.from_url(...)  # Crea nuova connessione ogni volta!
```

**Impatto**:
- Ogni chiamata a rate limiter crea una nuova connessione Redis
- Con 1000 utenti simultanei â†’ 1000+ connessioni Redis
- Redis ha limite default di 10000 connessioni, ma:
  - Ogni connessione consuma memoria
  - Overhead di gestione connessioni
  - Possibile esaurimento connessioni

**Soluzione**:
- Implementare connection pool per Redis sync
- Usare `redis.ConnectionPool` con max_connections
- Reutilizzare connessioni tra thread

**PrioritÃ **: ðŸ”´ CRITICA

---

### 2. ðŸŸ¡ MEDIO: PostgreSQL Pool Size Potrebbe Essere Insufficiente

**Situazione Attuale**:
- Pool: 25 base + 50 overflow = 75 max connessioni
- Con 100 utenti simultanei che fanno bulk sync â†’ 100 richieste
- Ogni bulk sync puÃ² usare 1-5 connessioni (chunk paralleli)

**Calcolo**:
- 100 utenti Ã— 3 chunk paralleli = 300 richieste potenziali
- Pool max 75 â†’ **COLLO DI BOTTIGLIA**

**Soluzione**:
- Aumentare `DB_POOL_SIZE` a 50-100 in produzione
- Aumentare `DB_MAX_OVERFLOW` a 100-200
- Monitorare metriche pool usage

**PrioritÃ **: ðŸŸ¡ MEDIA (dipende dal carico reale)

---

### 3. ðŸŸ¡ MEDIO: MySQL Pool Size Limitato

**Situazione Attuale**:
- Pool: 5 base + 5 overflow = 10 max connessioni
- Ogni blueprint mapping query usa 1 connessione
- Con bulk sync paralleli â†’ molti utenti cercano blueprint simultaneamente

**Calcolo**:
- 50 utenti Ã— 3 chunk paralleli Ã— 1 query blueprint = 150 richieste
- Pool max 10 â†’ **COLLO DI BOTTIGLIA SEVERO**

**Soluzione**:
- Aumentare `MYSQL_POOL_SIZE` a 20-30
- Aumentare `MYSQL_POOL_MAX_OVERFLOW` a 20-30
- Considerare Redis cache piÃ¹ aggressiva per blueprint mapping

**PrioritÃ **: ðŸŸ¡ MEDIA (ma puÃ² diventare critica con molti sync)

---

### 4. ðŸŸ¡ MEDIO: Isolated Engine Creation in Bulk Sync

**Problema**:
```python
async def get_isolated_db_session():
    engine = create_isolated_async_engine()  # Crea nuovo engine ogni volta!
    # ... usa engine ...
    await engine.dispose()  # Distrugge engine
```

**Impatto**:
- Ogni chunk bulk sync crea un nuovo engine SQLAlchemy
- Con 10 chunk paralleli â†’ 10 engine creati/distrutti
- Overhead di creazione/distruzione engine
- Memory churn

**Soluzione**:
- Considerare pool di engine isolati (piÃ¹ complesso)
- O limitare parallelismo chunk (meno performante)
- Monitorare memory usage

**PrioritÃ **: ðŸŸ¡ MEDIA (overhead accettabile per ora)

---

### 5. ðŸŸ¢ BASSO: Global Singleton Instances

**Problema**:
```python
_rate_limiter: Optional[RateLimiter] = None
_blueprint_mapper: Optional[BlueprintMapper] = None
```

**Impatto**:
- In ambiente multi-processo (Gunicorn/Uvicorn workers), ogni worker ha la propria istanza
- Non Ã¨ un problema reale, ma da documentare

**PrioritÃ **: ðŸŸ¢ BASSA (funziona correttamente)

---

### 6. ðŸŸ¡ MEDIO: Redis Async Client Singleton

**Problema**:
```python
_redis_client: Optional[Redis] = None  # Singleton globale
```

**Impatto**:
- Una sola connessione Redis async per processo
- Con molti worker FastAPI â†’ molte connessioni (OK)
- Ma se un worker ha molti task async simultanei â†’ potenziale bottleneck

**Soluzione**:
- Redis ha connection pooling interno
- Verificare che `aioredis.from_url` usi pooling
- Considerare connection pool esplicito se necessario

**PrioritÃ **: ðŸŸ¡ MEDIA (probabilmente OK, ma da monitorare)

---

## ðŸ“Š CALCOLI SCALABILITÃ€

### Scenario 1: 100 Utenti Simultanei
- **Bulk Sync**: 100 utenti Ã— 3 chunk = 300 richieste DB
- **PostgreSQL Pool**: 75 max â†’ **âš ï¸ INSUFFICIENTE**
- **MySQL Pool**: 10 max â†’ **ðŸ”´ CRITICO**
- **Redis Sync**: 100+ connessioni â†’ **ðŸ”´ CRITICO**

### Scenario 2: 50 Utenti Simultanei
- **Bulk Sync**: 50 utenti Ã— 3 chunk = 150 richieste DB
- **PostgreSQL Pool**: 75 max â†’ **âš ï¸ AL LIMITE**
- **MySQL Pool**: 10 max â†’ **ðŸ”´ CRITICO**
- **Redis Sync**: 50+ connessioni â†’ **âš ï¸ PROBLEMATICO**

### Scenario 3: 10 Utenti Simultanei
- **Bulk Sync**: 10 utenti Ã— 3 chunk = 30 richieste DB
- **PostgreSQL Pool**: 75 max â†’ âœ… OK
- **MySQL Pool**: 10 max â†’ **âš ï¸ AL LIMITE**
- **Redis Sync**: 10+ connessioni â†’ âœ… OK (ma inefficiente)

---

## ðŸ”§ RACCOMANDAZIONI PRIORITARIE

### PrioritÃ  1: ðŸ”´ CRITICA - Redis Sync Connection Pool

**File**: `app/core/redis_client.py`

**Implementazione**:
```python
_redis_sync_pool: Optional[redis.ConnectionPool] = None

def get_redis_sync():
    global _redis_sync_pool
    if _redis_sync_pool is None:
        _redis_sync_pool = redis.ConnectionPool.from_url(
            settings.REDIS_URL,
            encoding="utf-8",
            decode_responses=True,
            max_connections=50,  # Limite connessioni pool
        )
    return redis.Redis(connection_pool=_redis_sync_pool)
```

**Benefici**:
- Reutilizzo connessioni
- Limite controllato
- Meno overhead

---

### PrioritÃ  2: ðŸŸ¡ ALTA - Aumentare Pool Size

**File**: `app/core/config.py`

**Modifiche**:
```python
DB_POOL_SIZE: int = Field(default=50, description="...")  # Da 25 a 50
DB_MAX_OVERFLOW: int = Field(default=100, description="...")  # Da 50 a 100

MYSQL_POOL_SIZE: int = Field(default=20, description="...")  # Da 5 a 20
MYSQL_POOL_MAX_OVERFLOW: int = Field(default=20, description="...")  # Da 5 a 20
```

**Benefici**:
- Supporta piÃ¹ utenti simultanei
- Riduce attesa su pool esaurito

---

### PrioritÃ  3: ðŸŸ¡ MEDIA - Monitoring e Alerting

**Implementare**:
- Metriche pool usage (PostgreSQL, MySQL, Redis)
- Alert quando pool > 80% utilizzato
- Dashboard Grafana per visualizzazione

**Benefici**:
- Identificare problemi prima che diventino critici
- Capacity planning

---

## ðŸ“ˆ STIMA CAPACITÃ€ ATTUALE

### Con Configurazione Attuale:
- **Utenti Simultanei**: ~10-15 (con bulk sync)
- **Utenti Simultanei**: ~50-100 (senza bulk sync, solo query)

### Con Ottimizzazioni PrioritÃ  1+2:
- **Utenti Simultanei**: ~50-75 (con bulk sync)
- **Utenti Simultanei**: ~200-500 (senza bulk sync)

### ScalabilitÃ  Orizzontale:
- **Multi-istanza**: âœ… Supportata (stateless)
- **Load Balancer**: âœ… Funziona
- **Redis Shared**: âœ… Condiviso tra istanze
- **DB Shared**: âœ… PostgreSQL condiviso

---

## âœ… CONCLUSIONE

### Punti di Forza:
1. âœ… Architettura stateless
2. âœ… Rate limiting per-user isolato
3. âœ… Connection pooling implementato
4. âœ… Deadlock retry automatico
5. âœ… Pattern Saga per operazioni critiche

### Aree di Miglioramento:
1. ðŸ”´ **CRITICO**: Redis sync connection pool
2. ðŸŸ¡ **ALTO**: Aumentare pool size PostgreSQL/MySQL
3. ðŸŸ¡ **MEDIO**: Monitoring pool usage

### Raccomandazione Finale:
**Il sistema Ã¨ SOLIDO per 10-15 utenti simultanei con bulk sync.**
**Con le ottimizzazioni PrioritÃ  1+2, puÃ² gestire 50-75 utenti simultanei.**

**Per scale maggiori (>100 utenti simultanei):**
- Implementare tutte le ottimizzazioni
- Aggiungere monitoring
- Considerare read replicas per MySQL (blueprint queries)
- Considerare read replicas per PostgreSQL (query inventario)
